{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f2eccf5-2a32-44b6-9244-9389221be62e",
   "metadata": {},
   "source": [
    "### Question 1: What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "Web Scraping is a technique to extract a large amount of data from websites. Data extracted from websites by web scraping is in unstructured format. Web scraping helps to collect these unstructured data and convert it in a structured form.\n",
    "\n",
    "The web scrapping consists of two parts: a web crawler and a web scraper. A web crawler is an artificial intelligence technology that browses the internet to index and searches for the content by given links. Whereas, web scraper is a tool to extract the data from several websites quickly and effectively. The design of the scraper can vary greatly according to the complexity and scope of the project so that it can quickly and accurately extract the data. The crawler leads the scrapper and extracts the requested data.\n",
    "\n",
    "Many large websites, like Google, Twitter, Facebook, StackOverflow, etc. have API’s that allow you to access their data in a structured format. This is the best option, but there are other sites that don’t allow users to access large amounts of data in a structured form or they are simply not that technologically advanced. In that situation, it’s best to use Web Scraping to scrape the website for data.\n",
    "\n",
    "Uses of web scrapping- Data mining,Content aggregation,News Monitoring, Price comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59edf6b6-8259-49b0-8880-6d87b1bbb81e",
   "metadata": {},
   "source": [
    "### Question 2: What are the different methods used for Web Scraping?\n",
    "\n",
    "The most common methods used for Web Scraping are :\n",
    "(i) Human copy-and-paste.\n",
    "(ii) Text pattern matching.\n",
    "(iii) HTTP programming.\n",
    "(iv) HTML parsing.\n",
    "(v) DOM parsing.\n",
    "(vi) Vertical aggregation.\n",
    "(vii) Semantic annotation recognizing.\n",
    "(viii) Computer vision web-page analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d4681f-57a8-4e74-a442-f4de03bd8f00",
   "metadata": {},
   "source": [
    "####Question 3: What is Beautiful Soup? Why is it used?\n",
    "\n",
    "Beautiful Soup is a Python package for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping.\n",
    "\n",
    "Some key features that make beautiful soup unique are:\n",
    "(i) Beautiful Soup provides a few simple methods and Pythonic idioms for navigating, searching, and modifying a parse tree.\n",
    "(ii) It automatically converts incoming documents to Unicode and outgoing documents to UTF-8.\n",
    "(iii) It sits on top of popular Python parsers like lxml and html5lib, which allows us to try out different parsing strategies or trade speed for flexibility.\n",
    "\n",
    "Uses of BeautifulSoup : This library helps with isolating titles and links from webpages. It can extract all of the text from HTML tags, and alter the HTML bin the document with which we’re working."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f787383e-8673-4f3c-a509-fa54b863e214",
   "metadata": {},
   "source": [
    "####Question 4: Why is flask used in this Web Scraping project?\n",
    "\n",
    "Flask is a web framework written in python used for easy and fast web application development, and for configuring backend applications with the frontend in an easy way. It gives complete control to developers on how to access data. \n",
    "Flask is based on Werkzeug’s(WSGI) toolkit and Jinja templating engine.\n",
    "Flask provides different libraries, tools, and modules, and many functionalities like handling user requests, routing, sessions, form validation, etc that can be easily used to develop a blog website or any commercial website, etc.\n",
    "There is no requirement of any boilerplate code in a flask that preserves your application’s main function.\n",
    "A major advantage of using flask is easy setup, and freedom to build a structure of web application as per your rules. It means flask is not bound as Django to use a specific set of rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44dbe61-4e57-48f3-b642-e803b7bbbd2a",
   "metadata": {},
   "source": [
    "####Question 5: Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "Code pipeline and Beanstalk are the two AWS servives used in this project.\n",
    "\n",
    "(i) AWS CodePipeline is a fully managed continuous delivery service that helps you automate your release pipelines for fast and reliable application and infrastructure updates.\n",
    "It is a continuous delivery service you can use to model, visualize, and automate the steps required to release your software. You can quickly model and configure the different stages of a software release process. \n",
    "CodePipeline automates the steps required to release your software changes continuously. \n",
    "\n",
    "(ii) With Elastic Beanstalk, you can quickly deploy and manage applications in the AWS Cloud without having to learn about the infrastructure that runs those applications. \n",
    "Elastic Beanstalk reduces management complexity without restricting choice or control. \n",
    "You simply upload your application, and Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring. \n",
    "Elastic Beanstalk supports applications developed in Go, Java, .NET, Node.js, PHP, Python, and Ruby. \n",
    "When you deploy your application, Elastic Beanstalk builds the selected supported platform version and provisions one or more AWS resources, such as Amazon EC2 instances, to run your application.\\nWe can also perform most deployment tasks, such as changing the size of your fleet of Amazon EC2 instances or monitoring your application, directly from the Elastic Beanstalk web interface (console)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc20965-00ef-4a0d-bf1a-53e0b0e029d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f3b9b-090a-4f18-b891-7f8f0969bcc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
